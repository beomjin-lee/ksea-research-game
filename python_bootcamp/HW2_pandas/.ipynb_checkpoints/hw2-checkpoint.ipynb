{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ERG-190C] Homework 2: Pandas EPA Air Quality\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "[Introduction](#intro)<br>\n",
    "1 - [Downloading the Data](#data)<br>\n",
    "2 - [Preparing the Data](#prep)<br>\n",
    "3 - [Exploring Data with Pandas](#explore)<br>\n",
    "4 - [California Data](#cadata)<br>\n",
    "\n",
    "# Introduction <a id='intro'></a>\n",
    "\n",
    "In this homework, we will investigate air quality data retreived from the EPA. The main goal for this assignment is to understand how PM2.5 FRM/FEM Mass effects air quality. We will accomplish this by analyzing EPA data and utilizing pandas (a powerful Python data analysis toolkit). To give us a sense of how we think about each discovery we make and what next steps it leads to we will provide comments and insights along the way.\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "As we clean and explore these data, you will gain practice with:\n",
    "* Manipulating tables and parts of the table (column, index)\n",
    "* Identifying the type of data collected, missing values, anomalies, etc.\n",
    "* Computing numeric operations (mean, variance)\n",
    "* Merging and analyzing data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Downloading the Data<a id='data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import math\n",
    "import zipfile\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the assignment, run the cell below to set up some imports that we will need for this assignment:\n",
    "\n",
    "In many of these assignments (and future adventures as a data scientist) we will use os, zipfile, pandas, numpy, matplotlib.pyplot, and seaborn.  \n",
    "\n",
    "**Question 1.1:** Import each of these libraries `as` their commonly used abbreviations (e.g., `pd`, `np`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as #YOUR CODE HERE\n",
    "import pandas as #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this homework, we'll be working with air quality data from the EPA; we want to read the description of the data and download the data from the website.</div>\n",
    "\n",
    "A description of the data is [here](https://aqs.epa.gov/aqsweb/airdata/FileFormats.html#_hourly_data_files).\n",
    "\n",
    "We can then download the data. [Here is the site](https://aqs.epa.gov/aqsweb/airdata/download_files.html).\n",
    "\n",
    "To download the data, use a link like this:\n",
    "\n",
    "https://aqs.epa.gov/aqsweb/airdata/hourly_TYPE_YEAR.zip\n",
    "\n",
    "...where \"TYPE\" is the measurement we want and \"YEAR\" is the year.\n",
    "\n",
    "**Measurement | (TYPE)**  \n",
    "Ozone | (44201)  \n",
    "SO2 | (42401)  \n",
    "CO | (42101)  \n",
    "NO2 | (42602)  \n",
    "PM2.5 FRM/FEM Mass | (88101)  \n",
    "PM2.5 non FRM/FEM Mass | (88502)  \n",
    "PM10 Mass | (81102)  \n",
    "PM2.5 Speciation | (SPEC)  \n",
    "PM10 Speciation | (PM10SPEC)\n",
    "\n",
    "\n",
    "We'll focus on PM2.5 Mass (88101) from 2017 in the problem set. Although it's possible to download the dataset exclusively through the notebook environment, the dataset is too large (~4.5 million rows, 1.17GB in size!) to load and process in datahub given the memory constraint. Because of this, we'll be using a reduced version of this dataset which removes readings from certain states that we will not be working with.\n",
    "\n",
    "<br>\n",
    "Let's start by using Python to unzip the file and see how this data is laid out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reduced_PM25_2017.csv']\n"
     ]
    }
   ],
   "source": [
    "air_quality_path = Path('data/reduced_PM25_2017.zip')\n",
    "zf = zipfile.ZipFile(air_quality_path, 'r')\n",
    "print([f.filename for f in zf.filelist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is only one CSV file within the zip file. From here, we want to then get a sense of the structure of the data within the CSV.\n",
    "\n",
    "**Question 1.2:** Load the CSV file in the zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = ...\n",
    "with zf.open(f_name) as f:\n",
    "    for i in range(2):\n",
    "        print(f.readline().rstrip().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3:** Answer the following boolean expressions using `True` or `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all the files CSV files?\n",
    "all_files_appear_to_be_csv = ...\n",
    "\n",
    "# Do all the files have a header line?\n",
    "all_files_contain_headers = ...\n",
    "\n",
    "# Do all the strings in the file have quotes around them?\n",
    "strings_appear_quoted = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can then organize this data and read it better by putting it in a table! We will go over this in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 2: Preparing the Data<a id='prep'></a>\n",
    "\n",
    "We can see that the file contains a pretty descriptive header, and in fact these are explained in detail in the documentation at the url listed at the top of this notebook. Let's extract it. We are going to pretend there are multiple files in the zip file, and keep using `zf` to read the file and extract the information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Code</th>\n",
       "      <th>County Code</th>\n",
       "      <th>Site Num</th>\n",
       "      <th>Parameter Code</th>\n",
       "      <th>POC</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Parameter Name</th>\n",
       "      <th>Date Local</th>\n",
       "      <th>...</th>\n",
       "      <th>Units of Measure</th>\n",
       "      <th>MDL</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Qualifier</th>\n",
       "      <th>Method Type</th>\n",
       "      <th>Method Code</th>\n",
       "      <th>Method Name</th>\n",
       "      <th>State Name</th>\n",
       "      <th>County Name</th>\n",
       "      <th>Date of Last Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>23</td>\n",
       "      <td>88101</td>\n",
       "      <td>3</td>\n",
       "      <td>33.553056</td>\n",
       "      <td>-86.815000</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEM</td>\n",
       "      <td>183</td>\n",
       "      <td>Thermo Scientific 5014i or FH62C14-DHS w/VSCC ...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>2017-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>88101</td>\n",
       "      <td>3</td>\n",
       "      <td>61.205861</td>\n",
       "      <td>-149.824602</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>...</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEM</td>\n",
       "      <td>170</td>\n",
       "      <td>Met One BAM-1020 Mass Monitor w/VSCC - Beta At...</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>2017-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1005</td>\n",
       "      <td>88101</td>\n",
       "      <td>3</td>\n",
       "      <td>31.349200</td>\n",
       "      <td>-109.539683</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEM</td>\n",
       "      <td>170</td>\n",
       "      <td>Met One BAM-1020 Mass Monitor w/VSCC - Beta At...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Cochise</td>\n",
       "      <td>2017-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>88101</td>\n",
       "      <td>3</td>\n",
       "      <td>37.687526</td>\n",
       "      <td>-121.784217</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEM</td>\n",
       "      <td>170</td>\n",
       "      <td>Met One BAM-1020 Mass Monitor w/VSCC - Beta At...</td>\n",
       "      <td>California</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>2017-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>88101</td>\n",
       "      <td>3</td>\n",
       "      <td>37.687526</td>\n",
       "      <td>-121.784217</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>Micrograms/cubic meter (LC)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEM</td>\n",
       "      <td>170</td>\n",
       "      <td>Met One BAM-1020 Mass Monitor w/VSCC - Beta At...</td>\n",
       "      <td>California</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>2017-03-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Code  County Code  Site Num  Parameter Code  POC   Latitude  \\\n",
       "0           1           73        23           88101    3  33.553056   \n",
       "1           2           20        18           88101    3  61.205861   \n",
       "2           4            3      1005           88101    3  31.349200   \n",
       "3           6            1         7           88101    3  37.687526   \n",
       "4           6            1         7           88101    3  37.687526   \n",
       "\n",
       "    Longitude  Datum            Parameter Name  Date Local  \\\n",
       "0  -86.815000  WGS84  PM2.5 - Local Conditions  2017-01-01   \n",
       "1 -149.824602  WGS84  PM2.5 - Local Conditions  2017-01-06   \n",
       "2 -109.539683  WGS84  PM2.5 - Local Conditions  2017-01-01   \n",
       "3 -121.784217  WGS84  PM2.5 - Local Conditions  2017-01-01   \n",
       "4 -121.784217  WGS84  PM2.5 - Local Conditions  2017-01-01   \n",
       "\n",
       "          ...                      Units of Measure  MDL Uncertainty  \\\n",
       "0         ...           Micrograms/cubic meter (LC)  2.0         NaN   \n",
       "1         ...           Micrograms/cubic meter (LC)  5.0         NaN   \n",
       "2         ...           Micrograms/cubic meter (LC)  5.0         NaN   \n",
       "3         ...           Micrograms/cubic meter (LC)  5.0         NaN   \n",
       "4         ...           Micrograms/cubic meter (LC)  5.0         NaN   \n",
       "\n",
       "   Qualifier Method Type  Method Code  \\\n",
       "0        NaN         FEM          183   \n",
       "1        NaN         FEM          170   \n",
       "2        NaN         FEM          170   \n",
       "3        NaN         FEM          170   \n",
       "4        NaN         FEM          170   \n",
       "\n",
       "                                         Method Name  State Name County Name  \\\n",
       "0  Thermo Scientific 5014i or FH62C14-DHS w/VSCC ...     Alabama   Jefferson   \n",
       "1  Met One BAM-1020 Mass Monitor w/VSCC - Beta At...      Alaska  Anchorage    \n",
       "2  Met One BAM-1020 Mass Monitor w/VSCC - Beta At...     Arizona     Cochise   \n",
       "3  Met One BAM-1020 Mass Monitor w/VSCC - Beta At...  California     Alameda   \n",
       "4  Met One BAM-1020 Mass Monitor w/VSCC - Beta At...  California     Alameda   \n",
       "\n",
       "   Date of Last Change  \n",
       "0           2017-04-19  \n",
       "1           2017-05-30  \n",
       "2           2017-04-24  \n",
       "3           2017-03-22  \n",
       "4           2017-03-22  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with zf.open(f_name) as fh:\n",
    "    PM25_2017 = pd.read_csv(fh, low_memory=False)\n",
    "PM25_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1:** Look through the table and see what data types are within the table. In the following describe at least one potential problem with the above data. Consider issues with missing values and bad data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2:** Find the dimensions of the table to figure out how much data we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3:** With this information, we can address the question of granularity and answer the questions below.\n",
    "\n",
    "1. What is the granularity of the `PM25_2017` data frame? \n",
    "1. How many records are there?\n",
    "1. What does each record represent (e.g. a city, an hourly report, etc)?\n",
    "1. After reading up on the data formats [here](https://aqs.epa.gov/aqsweb/airdata/FileFormats.html#_hourly_data_files), what does MDL stand for and what is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell for scratch work\n",
    "# consider using groupby or value_counts() \n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4:** Create an array of all the unique state names in `PM25_2017`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_states = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5:** We can see that there are a lot of columns that are unneeded for this data analysis. Let's make a new dataframe with the information we need. Use pd.DataFrame to create a new table with 4 columns:\n",
    "1. `Date`: The column of dates corresponding to the `Date Local` column.\n",
    "1. `Time`: The time of day that sampling began on a 24-hour clock corresponding to the `Time Local` column.\n",
    "1. `Measurement`: The measured value in the standard units of measure for the parameter corresponding to the `Sample Measurement` column.\n",
    "1. `Units`: The unit of measure for the parameter corresponding to the `Units of Measure` column.\n",
    "1. `State`: The name of the state where the monitoring site is located.\n",
    "1. `County`: The name of the county where the monitoring site is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_table = pd.DataFrame(columns = [\"Date\", \"Time\", \"Measurement\", \"Units\", \"State\", \"County\"])\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "----\n",
    "\n",
    "## Section 3: Exploring Data with Pandas<a id='explore'></a>\n",
    "\n",
    "According to researchers at the International Journal of Environmental Research and Public Health, PM2.5 is observed with higher concentrations at night and lower concentrations at daytime [(Link to paper)](https://www.ncbi.nlm.nih.gov/pubmed/26426035).\n",
    "\n",
    "In this section we will analyze our data and see whether this claim proves true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** Using the table from Question 2.5, create a new table containing just data from New York in the Bronx County on 2017-01-01. Set the date as the index. There should be 24 rows in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_concentrations = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2:** After browsing at the time and the measurement in the table above, what do you notice about the concentration of PM2.5 throughout the day and throughout the night?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3:** We can also visualize this data and see how the PM2.5 concentrations fluctuate throughout the day. In order to better plot the x-axis, we must add a new column to `ny_concentrations` called `Hours` that correspond with the `Time` column. This is because the `Time` column contains strings and not numbers so we cannot plot them. \n",
    "\n",
    "Add the `Hours` column to `ny_concentrations` with a range of 0-24 and then plot `ny_concentrations` with `Hours` as the x-axis and `Measurement` as the y-axis. Don't forget a title and lables on the axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_concentrations['Hours'] = np.arange(...)\n",
    "ny_concentrations.plot(x='Hours', y='Measurement')\n",
    "plt.title(\"PM2.5 Concentrations in the Bronx\") \n",
    "plt.ylabel(\"PM2.5 Micrograms/cubic meter (LC)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4:** Describe the trend of the PM2.5 conentrations and why this data supports the statement \"PM2.5 is observed with higher concentrations at night and lower concentrations at daytime\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 4: California Data<a id='cadata'></a>\n",
    "\n",
    "Let's explore data that hits a little closer to home. In this section, we will look at air quality trends in California - more specifically Sonoma County. California is known for its wildfires and last year 5 California cities made it to the [top 10 worst cities for air quality in the United States and Canada](https://www.theguardian.com/cities/datablog/2017/feb/13/most-polluted-cities-world-listed-region). We will use data analysis to see how the fires have impacted PM2.5 cocentrations.\n",
    "\n",
    "<br>**Question 4.1:** Create a dataframe called `PM25_2017_CA` that just has PM2.5 2017 California data.\n",
    "\n",
    "*hint: it might help to use .loc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25_2017_CA = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Question 4.2:** There are still too many uneeded columns, create a table `ca_county_table` with just the columns `Date Local`, `Time Local`, `Sample Measurement`, `County Name`. Try to use the `PM25_2017_CA` table and `.loc`. Use the [EPA website](https://aqs.epa.gov/aqsweb/airdata/FileFormats.html#_hourly_data_files) to find out what indices belong to each of these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_county_table = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Question 4.3:** Find the mean PM2.5 concentrations in each county. \n",
    "\n",
    "*hint: `groupby` is a helpful operation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "<img src=\"sonoma_county_fire.jpeg\" width=400>\n",
    "\n",
    "The October Fire Siege that started on October 8 was the [‘worst fire disaster in California’s history’](http://www.berkeleyside.com/2017/10/14/whats-fire-northern-california) according to FEMA, the Federal Emergency Management Agency. The October Fire Siege has included 250 wildfires: “At the peak of the wildfires there were 21 major wildfires that, in total, have burned over 245,000 acres, 11,000 firefighters battled the destructive fires that at one time forced 100,000 to evacuate, destroyed an estimated 6,900 structures\". \n",
    "\n",
    "UC Berkeley students could smell and see the effects of Sonoma County fires as the smells of burning wood and ashes were in the air. October 14, 2017 was one of the peak days that the fires were burning and we will analyze its effects on PM2.5 concentrations on this day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4:** Using `ca_county_table`, create a table containing just information Sonoma County on October 14, 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonoma_county_table_oct14 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5:** Using `ca_county_table`, create a table containing just information Sonoma County on Ocotober 1, 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonoma_county_table_oct1 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.6:** Merge `sonoma_county_table_oct14` and `sonoma_county_table_oct1` on `Time Local` to compare their PM2.5 concentrations side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonoma_merge = ....\n",
    "sonoma_merge.rename(columns={'Sample Measurement_x':'Oct14 PM2.5', 'Sample Measurement_y':'Oct1 PM2.5'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.7:** Calcuate the mean PM2.5 measurements of both days. How do you think the PM2.5 concentrations will compare on these two dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Submission\n",
    "\n",
    "Congrats, you're done with homework 2!\n",
    "\n",
    "Before you submit, click **Kernel** --> **Restart & Clear Output**. Then, click **Cell** --> **Run All**. Then, go to the toolbar and click **File** -> **Download as** -> **.html** and submit the file through bCourses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "## Bibliography\n",
    "\n",
    "- Yao, Ling, et al. - PM2.5 observations during the day vs at night. https://www.ncbi.nlm.nih.gov/pubmed/26426035\n",
    "- Guardian News and Media - Air quality rankings in cities. https://www.theguardian.com/cities/datablog/2017/feb/13/most-polluted-cities-world-listed-region\n",
    "- Berkeleyside - Sonoma County fire facts. http://www.berkeleyside.com/2017/10/14/whats-fire-northern-california"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Melissa Ly\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
